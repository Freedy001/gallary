# 核心依赖
torch>=2.0.0
transformers>=4.51.0
sentencepiece>=0.1.99
protobuf>=3.20.0
pillow>=9.0.0
numpy>=1.24.0
requests>=2.28.0
httpx>=0.25.0

# LoRA 推理
peft>=0.7.0

# ONNX Runtime (可选，用于 ONNX 后端)
onnxruntime>=1.16.0

# FastAPI 服务
fastapi>=0.104.0
uvicorn>=0.24.0
python-multipart>=0.0.6

# Qwen3 提示词优化
accelerate>=0.26.0
huggingface_hub>=0.20.0

# llama-cpp-python CPU 加速（推荐用于 CPU 服务器）
llama-cpp-python

# 聚类算法
hdbscan>=0.8.33
umap-learn>=0.5.4
